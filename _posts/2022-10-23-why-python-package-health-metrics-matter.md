---
layout: single
title: "Why Thinking About Metrics Should be the First Thing That Any New Organization, Program or Project Does"
excerpt: "Collecting baseline data that aligns with the goals and outcomes of your project, program or organization is critical to do at the beginning. Here I briefly explain why Python package health metrics are so important to the long-term success of pyOpenSci."
author: "Leah Wasser"
permalink: /blog/why-python-package-health-metrics-matter
header:
    overlay_color: "#666"
    overlay_filter: 0.6
categories:
  - blog-post
  - highlight
  - python-packaging
  - peer-review
toc: true
comments: true
---


## Metrics are critical to the development of any program 

I've created a few open science focused programs now from the ground up. One at 
NEON and another at CU Boulder. When building a new program, one of the first 
things that I do (after defining the mission and goals) is to define the metrics 
that constitute success. 

These metrics are critical to define early because:

* They drive everything that you do
* And often they take time to develop
* It's critical to have solid baseline data. This baseline data needs to be collected from the start of your program as often, it can't be collected later, retrospectively.  

If you have evaluation or education in your professional background like I do, 
you may even
[create a logic model](https://thecompassforsbc.org/how-to-guide/how-develop-logic-model-0) to map activities to outcomes and goals. This logic 
model helps you define how 
to collect the data that you need to track outcome success. 

## Baseline data are critical to collect at the start of building a program or organization

As I am building the pyOpenSci program, I find myself thinking about what metrics 
around Python scientific open source software we want to track to better understand:

1. The outcomes of our activities
2. The overall health of packages in our growing pyOpenSci ecosystem (specific to our organization)
3. How/if we contributed to improving the health of packages in our ecosystem
4. How we are impacting the broader scientific python, open source community

### Baseline metrics collected from the start will help your future self when running or working in an organization

As mentioned above, collecting metrics from the start 
of your efforts allows you to get off the ground running with data that you can use to compare to future data. Thus while it may not be the work that you want to do, it will 
help your future self. 

For pyOpenSci, collecting metrics allows us in the future 
to evaluate our programs and adaptively change things to 
make sure we are getting the outcomes that we want. 

Outcomes such as 
* Scientists being better able to find packages that are maintained to support their workflows  
* Improved documentation in packages as a result of our reviews

### But what metrics should we collect about scientific Python packages?

[In a previous post,](/blog/2022-10-24-why-should-python-open-source-matter-science) I spoke 
generally about why open source should matter to you as a scientist and as a 
developer or package maintainer. 

To better understand what data we should be collecting to track our packages 
health over time, I went to Twitter to see what my colleagues around the world
had to say. That conversation resulted in some really interesting insights.

Most importantly, it allowed me to begin to break down and group metrics in 
terms of pyOpenSci goals. 


### Goals for package metrics

We hope that:

* Peer review improves Python package structure and usability. 
* Peer review in some way supports maintenance and/or responsible archiving when a package comes to life-end.
* Over time, the package is improved and maintained with possible contributions for those other than the maintainer. 

We need metrics to understand things like

* Community adoption of the package (are scientists using it?)
* Maintenance level of the package (are maintainers still working on it and fixing bugs?)
* Infrastructure (are tests setup to help identify if contributions break things? )
* Usability (is the package documented in a way that helps users quickly get started)


## Three Python open source software healthy metric "buckets" that pyOpenSci cares about

Based on all of the feedback, and what I *think* might be a start at what pyOpenSci  
needs to consider, I organized the conversation into three buckets:

1. Infrastructure
2. Maintenance 
3. Community adoption (and usability??)

These three buckets I think are all priorities of pyOpenSci.

Note: Diversity, Equity, Inclusion, and Accessibility (DEIA) are also of critical 
concern for pyOpenSci but I will save that for another post. 

[<i class="fas fa-hand-point-right"></i> Click here to read more about a Twitter conversation on python package health.](/blog/what-makes-a-python-package-healthy){: .btn .btn--info .btn--large}

## Thoughts? 

Leave any feedback that you have in the comments section below.